{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bca21b-37a3-493c-9f6e-9f8b07cfa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"facebook/esm2_t12_35M_UR50D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec35a3a8-eb44-4dd1-81aa-103ea96b3a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fadedd70f4e4251baacac4df5cde5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7295468e94fc0a8e7a527036ddd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b6b4c4ef93449f8e5481fb65e68cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30683a1c693c4bb690443e947770626a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/778 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57645897b5fd491aab7a81e85414e9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/136M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EsmForMaskedLM(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): EsmLMHead(\n",
       "    (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "    (layer_norm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=480, out_features=33, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, do_lower_case=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id).to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d274af-ea51-4edd-939c-328ca825fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2ef9b0-fea7-449f-bf58-b1e0866b29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tokenizer(seq, return_tensors=\"pt\", add_special_tokens=True)\n",
    "input_ids = enc[\"input_ids\"].to(device)\n",
    "attention_mask = enc[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efdcefb-575e-4823-90be-513fcd8055e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 0, 20, 15, 11,  5, 19, 12,  5, 15, 16, 10, 16, 12,  8, 18,  7, 15,  8,\n",
      "         21, 18,  8, 10, 16,  4,  9,  9, 10,  4,  6,  4, 12,  9,  7, 16,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b6b277-768e-4153-bfdc-57ba9ee901a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(input_ids = input_ids, attention_mask=attention_mask)\n",
    "    logits = out.logits\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0d2c73-2347-4e40-8c23-893a810ae8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 35])\n",
      "log_probs: torch.Size([1, 35, 33])\n",
      "vocab size: 33\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"log_probs:\", log_probs.shape)\n",
    "print(\"vocab size:\", log_probs.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "299c9b54-b8ad-4304-9a5d-9aa9a2df258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8633cb08-4c41-4aca-81c3-3e2d7c8da379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_position(input_ids, i_bio):\n",
    "    ids = input_ids.clone()\n",
    "    model_idx = i_bio\n",
    "    ids[0, model_idx] = MASK\n",
    "    return ids\n",
    "\n",
    "i_bio = 5\n",
    "ids_masked = mask_position(input_ids, i_bio)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_masked = model(input_ids=ids_masked, attention_mask=attention_mask).logits\n",
    "    logp_masked = torch.log_softmax(logits_masked, dim=-1)\n",
    "\n",
    "logp_pos= logp_masked[0, i_bio]\n",
    "\n",
    "wt_token= input_ids[0, i_bio].item()\n",
    "wt_logp = logp_pos[wt_token].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea36f7ac-aa34-44aa-992e-930cc36324ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT token id: 19 WT log-prob at pos 5: -3.7084124088287354\n"
     ]
    }
   ],
   "source": [
    "print(\"WT token id:\", wt_token, \"WT log-prob at pos 5:\", wt_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bf47c8-a0e4-466e-9aa4-a769b246672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS  = tokenizer.cls_token_id\n",
    "EOS  = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "546f2dec-8024-49ae-9a38-89a2eef6cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_site_wt_logprobs(input_ids, attention_mask):\n",
    "\n",
    "    ids = input_ids.clone()\n",
    "    lm = ids.shape[1]\n",
    "\n",
    "    mask_positions = torch.arange(1, lm-1, device=ids.device)\n",
    "    batch = ids.repeat(mask_positions.numel(), 1)\n",
    "    batch[torch.arange(mask_positions.numel()), mask_positions] = MASK\n",
    "    amask = attention_mask.repeat(mask_positions.numel(), 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=batch, attention_mask=amask).logits\n",
    "        logp = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "    wt_tokens = ids[0, mask_positions]\n",
    "    wt_logps = logp[torch.arange(mask_positions.numel()), mask_positions, wt_tokens]\n",
    "\n",
    "    return wt_logps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f084ff2-1cf1-47a1-bc94-91d471804f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT per-site log-probs shape: torch.Size([33])\n",
      "PLL (sum of site log-probs): -91.56507110595703\n",
      "Perplexity (pseudo): 16.033803939819336\n"
     ]
    }
   ],
   "source": [
    "wt_logps = per_site_wt_logprobs(input_ids, attention_mask)\n",
    "\n",
    "print(\"WT per-site log-probs shape:\", wt_logps.shape)\n",
    "print(\"PLL (sum of site log-probs):\", float(wt_logps.sum()))\n",
    "print(\"Perplexity (pseudo):\", float(( -wt_logps.mean() ).exp()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8f9126-2588-4cd9-b0cb-97a3ba4399aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2id = {tok: tokenizer.convert_tokens_to_ids(tok) for tok in tokenizer.get_vocab()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42a0f367-9bc8-45f2-ad7e-5b0e914467d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_logprob_single_mutation(input_ids, attention_mask, i_bio, mutant_aa):\n",
    "    ids_masked_1 = input_ids.clone()\n",
    "    ids_masked_1[0, i_bio] = MASK\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logp = torch.log_softmax(model(ids_masked_1, attention_mask=attention_mask).logits, dim=-1)[0, i_bio]\n",
    "\n",
    "    wt_token = input_ids[0, i_bio].item()\n",
    "    mut_token = tokenizer.convert_tokens_to_ids(mutant_aa)\n",
    "    return float(logp[mut_token] - logp[wt_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "550160f8-4e68-4fbb-8b97-7586498bee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {$\\delta$} log p at position 5 for V:  0.8428685665130615\n"
     ]
    }
   ],
   "source": [
    "print(r' {$\\delta$} log p at position 5 for V: ', delta_logprob_single_mutation(input_ids, attention_mask, 5, \"V\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e62705c-70bd-40d6-a4f3-b05bb1a1be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\n",
    "    \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQ\",\n",
    "    \"MKTAYIAKQRYISFVKSHFSRQLDEKLG\",  \n",
    "]\n",
    "\n",
    "\n",
    "enc = tokenizer(\n",
    "                seqs,\n",
    "                return_tensors='pt',\n",
    "                add_special_tokens=True,\n",
    "                padding=True,\n",
    "                truncation=False\n",
    "               )\n",
    "\n",
    "ids = enc[\"input_ids\"].to(device)\n",
    "amask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logp = torch.log_softmax(model(ids, attention_mask=amask).logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d558b6-6660-421b-966c-0c3e0235ba93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenMM (CUDA2)",
   "language": "python",
   "name": "openmm_ff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
