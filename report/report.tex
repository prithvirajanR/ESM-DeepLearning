\documentclass[12pt, a4paper]{article}

% ── Packages ──────────────────────────────────────────────
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=2.2cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath, amssymb}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{array}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{setspace}
\usepackage{parskip}

% ── Settings ──────────────────────────────────────────────
\graphicspath{{../report_figures/}}
\hypersetup{colorlinks=true, linkcolor=blue!60!black, citecolor=green!50!black, urlcolor=blue!70!black}
\setstretch{1.08}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small Variant Effect Prediction with ESM Models}
\fancyhead[R]{\small \thepage}
\renewcommand{\headrulewidth}{0.4pt}
\setlength{\headheight}{14pt}

\titleformat{\section}{\Large\bfseries}{\thesection.}{0.5em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection}{\normalsize\bfseries}{\thesubsubsection}{0.5em}{}

\titlespacing*{\section}{0pt}{0.8em}{0.4em}
\titlespacing*{\subsection}{0pt}{0.6em}{0.3em}
\titlespacing*{\subsubsection}{0pt}{0.4em}{0.2em}

\setlength{\intextsep}{6pt plus 2pt minus 2pt}
\setlength{\floatsep}{6pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{8pt plus 2pt minus 2pt}
\captionsetup{font=small, skip=4pt}

\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

% ── Title ─────────────────────────────────────────────────
\title{
    \vspace{-1.5cm}
    {\LARGE\bfseries Predicting Protein Variant Effects and Epistasis\\[4pt]
    Using ESM Protein Language Models}\\[10pt]
    {\large A Comparative Study of Probabilistic and Geometry-Based Scoring}\\[6pt]
    {\normalsize Amyloid Precursor Protein (APP / A4\_HUMAN) --- Seuma et al.\ 2021}
}
\author{Prithvirajan R \and Adina Nadeem \and Fazil Tarlan}
\date{February 2026}

\begin{document}
\maketitle
\thispagestyle{empty}

% ══════════════════════════════════════════════════════════
\begin{abstract}
\noindent
Protein language models (pLMs) trained on millions of evolutionary sequences show promise for predicting the functional effects of amino acid substitutions. However, it remains unclear which scoring paradigm---probability-based or geometry-based---better captures the link between sequence variation and biological phenotype. We systematically compare six scoring methods across three ESM model architectures on a deep mutational scanning (DMS) dataset of 14,483 experimentally characterised variants of the Amyloid Precursor Protein (APP). The probabilistic methods include Pseudo-Log-Likelihood (PLL), Masked Log-Likelihood Ratio (MLLR), Entropy-Weighted MLLR, Mutant-Only Marginal, and Ensemble MLLR. As an alternative, we test Embedding Distance Scoring (EDS), a geometry-based method that measures displacement in latent space. Our results show that MLLR and PLL with ESM-2 (650M) achieve the highest correlations ($\rho \approx 0.43$), while EDS achieves $\rho = 0.39$ at 500--1000$\times$ lower cost. Neither method reliably predicts epistasis, and prediction accuracy does not differ significantly between single and double mutants.
\end{abstract}

\newpage
\tableofcontents
\newpage

% ══════════════════════════════════════════════════════════
\section{Introduction}

\subsection{Motivation}

Engineering proteins with improved or novel function is central to biotechnology. The key challenge is navigating the protein \textbf{fitness landscape}---a vast, rugged surface mapping every possible sequence to its biological function. A 100-residue protein has $20^{100}$ possible sequences, and experimental approaches like deep mutational scanning (DMS) cost upwards of \$50,000 per experiment. Computational prediction using machine learning offers an attractive alternative: score variants \textit{in silico} and validate only the most promising candidates experimentally.

\textbf{Protein language models} (pLMs) are transformer-based neural networks trained on large databases of natural protein sequences via masked language modelling. By learning to predict masked amino acids from context, they implicitly encode evolutionary constraints governing protein structure and function. This study asks: \textbf{which scoring paradigm applied to these models is most reliable for predicting variant effects?}

\subsection{Models Tested}

We evaluate three models from the ESM family (Meta AI Research):

\begin{table}[H]
\centering
\caption{ESM models used in this study.}
\label{tab:models}
\begin{tabular}{llcll}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Layers} & \textbf{Training Data} & \textbf{Purpose} \\
\midrule
ESM-2 (150M) & 150 million & 30 & UniRef50 & Fast baseline \\
ESM-2 (650M) & 650 million & 33 & UniRef50 & Large generalist \\
ESM-1v (650M) & 650 million & 33 & UniRef90 & Variant specialist \\
\bottomrule
\end{tabular}
\end{table}

\subsection{The A4\_HUMAN Dataset}

We selected the A4\_HUMAN\_Seuma\_2021 dataset from ProteinGym---a DMS scan of the \textbf{Amyloid Precursor Protein (APP)}, whose misprocessing causes amyloid-$\beta$ plaque formation in Alzheimer's disease. The dataset was chosen for its human origin, clinical relevance, and exceptionally rich double-mutant coverage enabling epistasis analysis.

\begin{table}[H]
\centering
\caption{Dataset statistics.}
\begin{tabular}{lr}
\toprule
Total variants & 14,483 \\
Single mutants & 468 \\
Double mutants & 14,015 \\
DMS score range & $[-6.27, +3.33]$ \\
Phenotype & APP processing / toxicity \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Hypotheses}

\begin{enumerate}[label=\textbf{H\arabic*:}, leftmargin=2cm, noitemsep]
    \item pLMs predict single-mutant effects with significant correlation to experimental DMS scores.
    \item Probabilistic scoring (PLL, MLLR) is the most reliable paradigm; geometry-based scoring (EDS) is an alternative worth testing.
    \item Larger models improve predictions regardless of scoring method.
    \item Accuracy is significantly higher for single mutants than for doubles.
    \item The method with best epistasis prediction is most trustworthy for landscape exploration.
\end{enumerate}

% ══════════════════════════════════════════════════════════
\section{Methods}

\subsection{Scoring Methods}

We evaluate six methods grouped into two paradigms.

\subsubsection{Masked Log-Likelihood Ratio (MLLR)}
The standard approach in the pLM literature. Each mutated position is masked, and the model predicts a probability distribution over amino acids:
$\text{MLLR} = \log P(x_{\text{mut}} \mid x_{\setminus i}) - \log P(x_{\text{wt}} \mid x_{\setminus i})$.
Requires one forward pass per mutant. For multi-site mutations, scores are summed.

\subsubsection{Pseudo-Log-Likelihood (PLL)}
Evaluates every position: $\text{PLL}(x) = \sum_{i=1}^{L} \log P(x_i \mid x_{\setminus i})$.
Measures overall sequence ``naturalness.'' Requires $L$ forward passes ($L \approx 700$ for APP), making it $\sim$700$\times$ slower than MLLR. We also compute the Log-Likelihood Ratio (LLR = PLL(mut) $-$ PLL(WT)), which produces identical rankings.

\subsubsection{Entropy-Weighted MLLR}
Weights each position by inverse entropy: $\text{Score} = \text{LLR}_i / (H(x_i) + \varepsilon)$, penalising mutations at conserved (low-entropy) positions more heavily.

\subsubsection{Mutant-Only Marginal}
Absolute fitness: $\text{Score} = \log P(x_{\text{mut}} \mid x_{\setminus i})$---no wild-type comparison.

\subsubsection{Ensemble MLLR}
Averages MLLR over multiple passes with stochastic neighbour masking, testing context robustness.

\subsubsection{Embedding Distance Scoring (EDS)}
Our alternative, geometry-based approach:
$\text{EDS}(x) = -\| \mathbf{H}_{\text{mut}} - \mathbf{H}_{\text{wt}} \|_2$,
where $\mathbf{H} \in \mathbb{R}^{L \times D}$ is the final-layer hidden state tensor. Rather than asking ``is this sequence evolutionarily plausible?'', EDS asks ``how much did this mutation change the protein's meaning in latent space?'' (\textbf{Latent Manifold Hypothesis}). Requires only 2 forward passes per variant.

\subsection{Epistasis Analysis}

Epistasis captures non-additive mutation interactions:
$E = \text{Score}(AB) - \text{Score}(A) - \text{Score}(B) + \text{Score}(\text{WT})$.

For PLL (absolute scores $\approx -400$), this formula requires a WT-baseline correction to avoid double-counting; our pipeline auto-detects and corrects this. For EDS (WT $\approx 0$), no correction is needed.

\subsection{Landscape Exploration}

We generated 4,000 synthetic mutants (1,000 each at $k = 2, 5, 10, 20$ substitutions) and scored them with EDS and PLL to measure fitness decay across mutational distance.

\subsection{Technical Setup}

All scoring ran on the RAVEN HPC cluster (MPCDF) with NVIDIA A100 GPUs. Wall times ranged from $\sim$30 min (EDS) to $\sim$24 h (PLL 650M). CSV-based checkpointing ensured robustness. Statistical tests use Spearman's $\rho$, permutation tests ($n = 10{,}000$), and bootstrap 95\% confidence intervals.


% ══════════════════════════════════════════════════════════
\section{Results}

\subsection{Initial Validation (Phase 1)}

As a sanity check, we ran MLLR with ESM-2 (150M) on 468 single mutants (CPU only).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{baseline_masked_marginal_correlation.png}
    \caption{Initial validation: ESM-2 (150M) Masked Marginal scores vs.\ experimental DMS fitness for 468 single mutants ($\rho = 0.25$, $p = 5 \times 10^{-8}$). This confirmed the pipeline works and justified scaling up.}
    \label{fig:baseline}
\end{figure}

\subsection{Comprehensive Benchmark (18 Configurations)}

We ran all six scoring methods across all three models on the full 14,483-variant dataset.

\begin{table}[H]
\centering
\caption{Full benchmark leaderboard sorted by Spearman $\rho$ within each model group. Run times on NVIDIA A100.}
\label{tab:leaderboard}
\small
\begin{tabular}{llccc}
\toprule
\textbf{Model} & \textbf{Method} & \textbf{Spearman $\rho$} & \textbf{Top-100 Prec.} & \textbf{Run Time} \\
\midrule
\multicolumn{5}{l}{\textit{ESM-2 (650M)}} \\
\midrule
ESM-2 (650M) & MLLR              & \textbf{0.427} & 57\%  & $\sim$4 h \\
ESM-2 (650M) & PLL               & 0.425 & 69\%  & $\sim$24 h \\
ESM-2 (650M) & Ensemble MLLR     & 0.423 & 39\%  & $\sim$24 h \\
ESM-2 (650M) & Entropy-MLLR      & 0.420 & 5\%   & $\sim$5 h \\
ESM-2 (650M) & EDS               & 0.388 & \textbf{93\%} & $\sim$40 min \\
ESM-2 (650M) & Mutant Marginal   & 0.365 & 31\%  & $\sim$5 h \\
\midrule
\multicolumn{5}{l}{\textit{ESM-2 (150M)}} \\
\midrule
ESM-2 (150M) & Entropy-MLLR      & 0.385 & 47\%  & $\sim$1 h \\
ESM-2 (150M) & MLLR              & 0.371 & 55\%  & $\sim$1 h \\
ESM-2 (150M) & Ensemble MLLR     & 0.363 & 49\%  & $\sim$5 h \\
ESM-2 (150M) & PLL               & 0.339 & 73\%  & $\sim$16 h \\
ESM-2 (150M) & EDS               & 0.270 & 87\%  & $\sim$10 min \\
ESM-2 (150M) & Mutant Marginal   & 0.247 & 40\%  & $\sim$1 h \\
\midrule
\multicolumn{5}{l}{\textit{ESM-1v (650M)}} \\
\midrule
ESM-1v (650M) & EDS              & 0.339 & 89\%  & $\sim$40 min \\
ESM-1v (650M) & Ensemble MLLR    & 0.329 & 82\%  & $\sim$5 h \\
ESM-1v (650M) & Mutant Marginal  & 0.292 & 77\%  & $\sim$1 h \\
ESM-1v (650M) & MLLR             & 0.290 & 48\%  & $\sim$1 h \\
ESM-1v (650M) & PLL              & 0.236 & 76\%  & $\sim$20 h \\
ESM-1v (650M) & Entropy-MLLR     & 0.228 & 86\%  & $\sim$1 h \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Probabilistic Methods Dominate}

The top five configurations by Spearman $\rho$ are all probabilistic, with ESM-2 (650M). MLLR ($\rho = 0.427$) and PLL ($\rho = 0.425$) are nearly identical, despite PLL being $\sim$700$\times$ more expensive. This suggests the information at mutation sites dominates, and the global context PLL provides is largely redundant. \textbf{MLLR should be preferred over PLL for practical applications.}

\subsubsection{Model Size Consistently Helps}

Scaling from 150M to 650M improves all methods. EDS benefits most (+0.118), followed by PLL (+0.086) and MLLR (+0.056). ESM-1v, despite equal size to ESM-2 (650M), consistently underperforms---likely because its UniRef90 training data introduces noise for this specific protein.

\subsubsection{EDS as a Practical Alternative}

While probabilistic methods achieve the highest Spearman $\rho$, EDS dominates the \textbf{Top-100 Precision} metric across all models (93\% for ESM-2 650M, 89\% for ESM-1v, 87\% for ESM-2 150M). This means that if one selects the top 100 variants ranked by EDS, over 87\% are true positives in the DMS assay. Combined with $\sim$500$\times$ faster computation than PLL, EDS is the clear winner for practical library design and screening applications.

\subsection{Benchmark Report Plots}

Each benchmark report shows three panels: a prediction scatter plot of model score versus experimental DMS fitness (left), score distributions separated by functional class (centre), and a ROC curve for binary classification (right).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM2_650M_MLLR.png}
    \caption{\textbf{ESM-2 (650M) + MLLR} ($\rho = 0.427$) --- the top-performing configuration overall.}
    \label{fig:bench_mllr}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM2_650M_PLL.png}
    \caption{\textbf{ESM-2 (650M) + PLL} ($\rho = 0.425$) --- nearly identical to MLLR despite being $\sim$700$\times$ more expensive.}
    \label{fig:bench_pll}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM2_650M_EnsembleMLLR.png}
    \caption{\textbf{ESM-2 (650M) + Ensemble MLLR} ($\rho = 0.423$, Top-100 Precision = 13\%) --- best precision among all methods.}
    \label{fig:bench_ensemble}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM2_650M_EDS.png}
    \caption{\textbf{ESM-2 (650M) + EDS} ($\rho = 0.388$) --- the geometry-based alternative. Competitive correlation with far lower computational cost.}
    \label{fig:bench_eds}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM2_150M_MLLR.png}
    \caption{\textbf{ESM-2 (150M) + MLLR} ($\rho = 0.371$) --- smaller model, reduced but still meaningful performance.}
    \label{fig:bench_150m}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{bench_ESM1v_MLLR.png}
    \caption{\textbf{ESM-1v + MLLR} ($\rho = 0.290$) --- the variant-specialist model underperforms on this dataset despite having 650M parameters.}
    \label{fig:bench_esm1v}
\end{figure}

\subsection{Epistasis Analysis}

We computed epistasis for all 14,015 double mutants using both EDS and PLL.

\begin{table}[H]
\centering
\caption{Predicted epistasis distributions ($n = 14{,}015$).}
\begin{tabular}{lccl}
\toprule
\textbf{Method} & \textbf{Mean} & \textbf{Std} & \textbf{Interpretation} \\
\midrule
EDS & +3.31 & 0.80 & Systematic positive (triangle inequality) \\
PLL (corrected) & +0.11 & 1.23 & Near-zero (log-additive) \\
Experimental & $-0.25$ & 0.97 & Mild negative (synergistic damage) \\
\bottomrule
\end{tabular}
\end{table}

EDS predicts universal positive epistasis due to the triangle inequality ($\|A+B\|_2 \leq \|A\|_2 + \|B\|_2$). PLL predicts near-zero epistasis reflecting its inherent log-additivity. Neither captures the mild negative epistasis observed experimentally.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{epistasis_EDS_scatter.png}
        \caption{EDS: observed vs.\ expected}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{epistasis_PLL_scatter.png}
        \caption{PLL: observed vs.\ expected}
    \end{subfigure}
    \caption{Epistasis scatter plots ($n = 14{,}015$ doubles). EDS (a) shows a systematic upward offset from the diagonal---positive epistasis caused by the triangle inequality. PLL (b) lies along the diagonal, reflecting log-additivity.}
    \label{fig:epistasis_scatter}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{epistasis_EDS_distribution.png}
        \caption{EDS epistasis distribution}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{epistasis_PLL_distribution.png}
        \caption{PLL epistasis distribution}
    \end{subfigure}
    \caption{Epistasis value distributions. EDS (a) is centred at +3.3 (systematic buffering). PLL (b) is centred near zero (additive). The experimental mean is $-0.25$.}
    \label{fig:epistasis_dist}
\end{figure}

\textbf{Predicted vs.\ experimental epistasis} correlation is negligible for both methods (EDS: $\rho = 0.027$, $p = 0.001$; PLL: $\rho = -0.013$, $p = 0.14$). This is consistent with published literature---epistasis prediction from single-sequence pLMs remains an open problem.

\subsection{Hypothesis Testing}

\subsubsection{H4: Single vs.\ Double Mutant Prediction}

\begin{table}[H]
\centering
\caption{H4: Spearman $\rho$ for singles ($n=468$) vs.\ doubles ($n=14{,}015$).}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{$\rho_{\text{singles}}$ [CI]} & \textbf{$\rho_{\text{doubles}}$ [CI]} & \textbf{$\Delta\rho$} & \textbf{$p_{\text{perm}}$} \\
\midrule
EDS & 0.448 [0.374, 0.516] & 0.381 [0.367, 0.395] & +0.067 & 0.084 \\
PLL & 0.236 [0.151, 0.315] & 0.226 [0.210, 0.241] & +0.010 & 0.819 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{hypothesis_H4_barplot.png}
    \caption{H4: Single vs.\ double mutant prediction accuracy for EDS and PLL. Error bars show 95\% bootstrap confidence intervals. Neither method shows a statistically significant difference between singles and doubles.}
    \label{fig:h4}
\end{figure}

\textbf{Verdict: H4 NOT supported.} Singles are predicted slightly better, but the difference is not significant ($p > 0.05$ for both methods).

\subsubsection{H5: Epistasis Accuracy and Landscape Trust}

\begin{table}[H]
\centering
\caption{H5: Linking epistasis accuracy to overall prediction quality.}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Epistasis $\rho$} & \textbf{Sign Agr.} & \textbf{Overall $\rho$} & \textbf{Best?} \\
\midrule
EDS & 0.027 & 36.2\% & 0.388 & \checkmark \\
PLL & $-0.013$ & 50.6\% & 0.235 & --- \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{hypothesis_H5_epistasis.png}
    \caption{H5: Comparison of epistasis prediction accuracy and overall prediction quality for EDS and PLL. EDS has higher (though small) epistasis correlation and substantially better overall Spearman $\rho$.}
    \label{fig:h5}
\end{figure}

\textbf{Verdict: H5 SUPPORTED with caveats.} EDS is the stronger method on both epistasis and overall prediction, but neither method predicts epistasis well in absolute terms.

\subsection{Landscape Exploration}

Both EDS and PLL show clear, monotonic fitness decay across 4,000 synthetic mutants at increasing mutational distances.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{landscape_decay_EDS.png}
    \caption{EDS fitness decay with mutational distance. Box plots show score distributions at $k = 2, 5, 10, 20$ mutations. Fitness drops monotonically but sub-linearly, reflecting the saturation effect of the triangle inequality.}
    \label{fig:landscape_decay_eds}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{landscape_decay_PLL.png}
    \caption{PLL fitness decay with mutational distance. PLL drops roughly proportionally to $k$, consistent with the additive (position-independent) nature of log-likelihoods.}
    \label{fig:landscape_decay_pll}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{landscape_violin_EDS.png}
    \caption{Violin plots of EDS score distributions at each mutational distance. The distributions widen with increasing $k$, indicating greater variance among highly mutated sequences.}
    \label{fig:landscape_violin_eds}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{landscape_violin_PLL.png}
    \caption{Violin plots of PLL score distributions at each mutational distance. The narrower distributions compared to EDS reflect PLL's more linear response to cumulative mutations.}
    \label{fig:landscape_violin_pll}
\end{figure}

PLL's decay is roughly proportional to $k$, consistent with position-wise additivity. EDS shows sub-linear decay as embedding displacements from different mutations partially overlap. The two methods correlate strongly across the landscape (Spearman $\rho = 0.936$), confirming both capture the same underlying topology.


% ══════════════════════════════════════════════════════════
\section{Discussion}

\subsection{Probabilistic Scoring as the Recommended Approach}

MLLR and PLL with ESM-2 (650M) achieve the best results ($\rho \approx 0.43$). Since they perform nearly identically but MLLR is $\sim$700$\times$ faster, \textbf{MLLR is the recommended method} for most applications. PLL is often considered the ``gold standard'' because it evaluates the full sequence, but our results show this comprehensiveness does not translate into measurably better predictions. Researchers with limited computational resources can confidently use MLLR without sacrificing accuracy.

\subsection{The Effect of Model Scale}

Scaling from 150M to 650M parameters improves every scoring method we tested, but the magnitude of improvement varies considerably:

\begin{table}[H]
\centering
\caption{Effect of model scaling: Spearman $\rho$ improvement from ESM-2 (150M) to ESM-2 (650M).}
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{150M} & \textbf{650M} & \textbf{$\Delta\rho$} \\
\midrule
MLLR & 0.371 & 0.427 & +0.056 \\
PLL & 0.339 & 0.425 & +0.086 \\
Entropy-MLLR & 0.385 & 0.420 & +0.035 \\
Ensemble MLLR & 0.363 & 0.423 & +0.060 \\
EDS & 0.270 & 0.388 & +0.118 \\
\bottomrule
\end{tabular}
\end{table}

EDS benefits by far the most from scaling (+0.118): a larger model produces a more structured representation space, giving geometric distances greater discriminative power. PLL also benefits substantially (+0.086), while Entropy-MLLR shows the smallest gain (+0.035), likely because entropy weighting already compensates for some limitations of smaller models. ESM-1v, despite equal parameter count to ESM-2 (650M), consistently underperforms---its UniRef90 training data may introduce noise for the conserved APP transmembrane domain.

\subsection{EDS: Geometry Beats Probability for Precision}

EDS is not merely a cheaper alternative---it is the \textbf{precision champion}. With 93\% Top-100 Precision on ESM-2 (650M), EDS outperforms every probabilistic method by a wide margin (the next best is PLL at 69\%). This suggests that embedding distance better captures ``functional phenotype'' (aggregation/activity) while log-likelihood better captures ``evolutionary fitness'' (survival). For drug discovery or library design, where selecting the right candidates matters more than ranking everyone perfectly, EDS with ESM-2 (650M) is the recommended approach: best precision, fastest runtime ($\sim$40 min vs.\ $\sim$24 h for PLL).

\subsection{The Epistasis Limitation}

Neither paradigm predicts epistasis reliably. Current pLMs process positions largely independently via masking, missing coupled effects of simultaneous mutations. EDS's positive bias (triangle inequality) and PLL's near-zero prediction (log-additivity) both fail to capture the mild negative epistasis observed experimentally. While pLMs can rank overall multi-mutant quality, they should not be trusted for identifying synergistic or compensatory mutation pairs. Future approaches might incorporate structural information or train on paired mutation data.

\subsection{Practical Recommendations}

\begin{enumerate}[noitemsep]
    \item \textbf{Ranking/screening:} MLLR with ESM-2 (650M) --- best accuracy, one pass per variant.
    \item \textbf{High-throughput pre-screening:} EDS with ESM-2 (650M) --- competitive accuracy at minimal cost.
    \item \textbf{Mechanistic insight:} PLL/LLR for interpretable evolutionary fitness scores.
    \item \textbf{Avoid:} Relying on predicted epistasis for combinatorial design; using ESM-1v unless specifically validated.
\end{enumerate}

\subsection{Limitations}

Our conclusions are based on a single dataset (A4\_HUMAN) and may not generalise to proteins under different selective pressures. We did not incorporate structural information (AlphaFold, MSA features), and EDS uses only Euclidean distance---cosine or learned metrics might perform differently. The DMS assay measures a specific phenotype that may not align perfectly with the evolutionary constraints captured by pLMs.


% ══════════════════════════════════════════════════════════
\section{Conclusion}

We present a systematic comparison of six scoring methods across three ESM protein language models on the APP deep mutational scanning dataset. Our key findings:

\begin{enumerate}[noitemsep]
    \item \textbf{Probabilistic methods rank best overall.} MLLR with ESM-2 (650M) achieves the best correlation ($\rho = 0.427$) and should be preferred over PLL given equivalent accuracy at far lower cost.
    \item \textbf{Geometry-based scoring dominates precision.} EDS achieves 93\% Top-100 Precision---the best across all methods---at orders-of-magnitude lower computational cost. For practical library design, EDS is the recommended choice.
    \item \textbf{Epistasis prediction remains unsolved.} Neither paradigm captures non-additive mutation interactions from sequence alone.
    \item \textbf{Model size matters more than specialisation.} ESM-2 (650M) outperforms both the smaller 150M variant and the similarly-sized ESM-1v on every method.
    \item \textbf{The fitness landscape is smooth.} Both methods show clear, monotonic fitness decay ($\rho = 0.936$ between methods), confirming pLMs capture the overall landscape topology.
\end{enumerate}


% ══════════════════════════════════════════════════════════
\section*{References}
\begin{enumerate}[label={[\arabic*]}, leftmargin=2cm, noitemsep]
    \item Seuma, M., Faure, A.\,J., Badia, M., Lehner, B., \& Bolognesi, B. (2021). The genetic landscape for amyloid beta fibril nucleation accurately discriminates familial Alzheimer's disease mutations. \textit{eLife}, 11, e63364.
    \item Lin, Z., et al. (2023). Evolutionary-scale prediction of atomic-level protein structure with a language model. \textit{Science}, 379(6637), 1123--1130.
    \item Meier, J., et al. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. \textit{NeurIPS}, 34.
    \item Notin, P., et al. (2023). ProteinGym: Large-Scale Benchmarks for Protein Design and Fitness Prediction. \textit{NeurIPS Datasets and Benchmarks}.
    \item Rives, A., et al. (2021). Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. \textit{PNAS}, 118(15).
    \item Frazer, J., et al. (2021). Disease variant effect prediction with protein language models. \textit{Nature}, 599, 91--95.
\end{enumerate}

\end{document}
